{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4269864",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Causal Inference Crash Course:\n",
    "## Arguable Validation for Cross-Sectional Models\n",
    "Julian Hsu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc3db7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "* Since panel models are relatively more straight-forward to test such as testing pre-treatment time parallel trends, this presentation focuses on arguable validation for cross-sectional models.\n",
    "* We will also focus on standard propensity-based models, excluding approaches such as instrumental variable and regression discontinuity.\n",
    "* We will cover some strategies:\n",
    "    * Placebo tests\n",
    "    * Coefficient stability following Oster (2019)\n",
    "    * Feature balancing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763d3fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What are we arguably validating?\n",
    "* We are interested in estimating some treatment effect. \n",
    "    * Ie, the impact of a selection change in a store’s OPS.\n",
    "* Recall the challenge is that we do not observe counterfactual outcomes – what the treatment observations’ outcome would be if they were instead treated, or vice versa.\n",
    "    * We don’t know what the store’s OPS would be if we did not change selection.\n",
    "* We rely on assumptions like exogeneity, under which we can expect our model estimates the true treatment effect\n",
    "* So we are trying to validate the assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30dece",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Actions you may take based on arguable validation\n",
    "* Suppose you ran this OLS equation:\n",
    "$$ Y_i = \\hat{\\tau} W_i + \\hat{\\beta}_1 X_i + \\epsilon_i$$\n",
    "for an outcome $Y_i$, treatment indicator $W_i$, and features $X_i$.\n",
    "* What if you get an different estimate of if you ran:\n",
    "$$ Y_i = \\hat{\\tau} W_i + \\hat{\\beta}_1 X_i^2 + \\epsilon_i$$\n",
    "$$ Y_i = \\hat{\\tau} W_i + \\hat{\\beta}_1 X_i + \\hat{\\beta}_2 Z_i + \\epsilon_i$$\n",
    "* Arguable validation helps you decide which model you should trust.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e451863",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arguable validation of design\n",
    "* You may draw the conclusion that across all modeling specifications, you still don’t have a good estimate of ! In this case, you need to either:\n",
    "    * Choose a different design like difference-in-difference or regression discontinuity;\n",
    "    * Deep dive your use case to find the natural experiment in your data; or\n",
    "    * Understand the potential biases your design has.\n",
    "* Given the breadth of options above, we will just focus on arguable validation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f255faf",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os as os\n",
    "\n",
    "fig,ax = plt.subplots(ncols=1,nrows=1, figsize=(5,3))\n",
    "\n",
    "ax.set_xlabel('Reliability')\n",
    "ax.set_ylabel('Feasibility')\n",
    "\n",
    "ax.set_xticks([0.1,1])\n",
    "ax.set_xticklabels(labels=['Low','High'])\n",
    "\n",
    "ax.set_yticks([0.1,1])\n",
    "ax.set_yticklabels(labels=['Not Very','Very'])\n",
    "\n",
    "ax.text(x=0.05, y=0.5, s='Feature Balancing')\n",
    "ax.text(x=0.5,  y=0.6, s='Coefficient Stability')\n",
    "ax.text(x=0.7,  y=0.4, s='Placebo Test')\n",
    "ax.text(x=0.8,  y=0.3, s='Experiment')\n",
    "fig.set_facecolor('coral')\n",
    "plt.savefig(os.getcwd() + '/Figures/'+'ArguableValidation_Figure_1.png'\n",
    "           , bbox_inches='tight')\n",
    "\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c5668",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## High Level\n",
    "\n",
    "![Image](Figures/ArguableValidation_Figure_1.png)\n",
    "\n",
    "* Depending on your use case, you may use different ways to arguably validate your causal model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c87da6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Placebo Test\n",
    "Easy to do, except when it isn’t.\n",
    "\n",
    "Not a lot of wiggle room for pivoting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c751fc53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Big Idea\n",
    "$$ Y_i = \\hat{\\tau} W_i + \\hat{\\beta}_1 X_i + \\epsilon_i$$\n",
    "\n",
    "* Are there outcomes for which we know the treatment effect ?\n",
    "* A placebo outcome is one where we know the treatment effect is zero.\n",
    "$$ Y^{placebo}_i = \\hat{\\tau}^{placebo} W_i + \\hat{\\alpha}_1 X_i + \\eta_i$$\n",
    "\n",
    "* Placebo outcomes can help transform the causal validation to a traditional prediction one, because we have a “ground truth” value for $\\hat{\\tau}^{placebo}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d34b412",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Make a Covariate an Outcome\n",
    "* A popular placebo is the outcome before the treatment: $Y^{pre}_i$\n",
    "\n",
    "$$ Y^{pre}_i = \\hat{\\tau}^{placebo} W_i + \\hat{\\alpha}_1 X_i + \\eta_i$$\n",
    "\n",
    "* And we want to see whether $\\hat{\\tau}^{placebo}$ is statistically different from zero\n",
    "* We could pick any features populated before the treatment, but the $Y^{pre}_i$ is particularly good because it looks very similar to $Y_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea66b2",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Make a point that we are still controlling for the same stuff. This will come into feasability later.\n",
    "* It's good that our placebo outcome has a similar distribution to the regular outcome so we do not invite additional problems to estimation and training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fd9156",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feasibility - what if $Y^{pre}_i$ is $X_i$ ? \n",
    "* This approach sacrifices data. You will have one fewer control variable, or have one fewer pre-treatment period of data.\n",
    "    * If $Y^{pre}_i$ is the only thing you are controlling for, then you obviously can’t use it as a placebo outcome.\n",
    "* Sacrificing this data has risks if you think $Y^{pre}_i$ is uniquely important for predicting $Y_i$ and $W_i$.\n",
    "\n",
    "\\begin{array}{rl}\n",
    " Y_i = & \\hat{\\tau} W_i + \\hat{\\beta}_1 X_i + \\epsilon_i \\\\\n",
    " Y^{pre}_i = & \\hat{\\tau}^{placebo} W_i + \\hat{\\alpha}_1 X_i + \\eta_i \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0152636",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Drawbacks\n",
    "* If you think that exogeneity does not hold once you no longer control for the placebo outcome (ie $ Y^{pre}_i$), then you can’t use it as a placebo outcome. \n",
    "* You can test this by:\n",
    "    1. Seeing whether varies over whether you control for $ Y^{pre}_i$ or not; or\n",
    "    2. You determine whether $ Y^{pre}_i$ is crucial for predicting $Y_i$ or $W_i$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367fe37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2afe1477",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Coefficient stability \n",
    "Easy to do but requires some judgement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c927c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup \n",
    "\n",
    "$$  Y_i = \\hat{\\tau} W_i + \\hat{\\beta}_1 X_i + \\epsilon_i $$\n",
    "* Variation in $Y_i$ is explained by:\n",
    "1. observed control variables $X_i$;\n",
    "2. the treatment $W_i$; \n",
    "3. unobserved variables $\\epsilon_i$.\n",
    "*  As we control for more observable things, the remaining unexplained variation must be 2. or 3.\n",
    "* So the more features I control for, the closer I get to an unbiased estimate of $\\hat{\\tau}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2537fe09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The big idea\n",
    "* We need to look at how and explained variation in $Y_i$  change as we control for more things.\n",
    "* For example, we can find that controlling for more things doesn’t change$\\hat{\\tau}$. But if it doesn’t change $R^2$ either, then we could still be  missing something.\n",
    "* We should be more confident in our estimate $\\hat{\\tau}$ of under Scenario 2 and Scenario 1, below:\n",
    "\n",
    "| Control for ... features | Scenario 1's ($\\hat{\\tau}, R^2$) | Scenario 2's ($\\hat{\\tau}, R^2$)|\n",
    "|:---|:---:|:---:|\n",
    "|400| 5, 0.25 | 5, 0.25 | \n",
    "|1000| 5, 0.27 | 5, 0.90 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b42f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coefficient stability test and interpretation\n",
    "* “Given I can explain 99.9% of the variation $Y_i$ after controlling for $X_i$and that my estimate of is 10, how much selection bias is needed such that the incremental $X_i$ needed for me to explain 100% of the variation changes to 5?” \n",
    "* Oster (2019) uses the omitted variable bias formula, the $R^2$ formula, and assumptions on what the selection bias might look like to answer this question. I won’t go into this test statistic (shown below) for simplicity, but will show it in action in simulations\n",
    "\n",
    "$$\\delta^* =$$\n",
    "$$ \\dfrac{(\\tilde{\\beta} - \\hat{\\beta}) (\\tilde{R} - \\dot{R}) \\hat{\\sigma}^2_y \\hat{\\tau}_x + (\\tilde{\\beta} - \\hat{\\beta})\\hat{\\sigma}^2_x \\hat{\\tau}_x (\\dot{\\beta} - \\tilde{\\beta})^2 + 2A   }{(R_{max} - \\tilde{R}) \\hat{\\sigma}^2_y (\\dot{\\beta} - \\tilde{\\beta})\\hat{\\sigma}^2_x + (\\tilde{\\beta} - \\hat{\\beta})(R_{max} - \\tilde{R})\\hat{\\sigma}^2_y (\\hat{\\sigma}^2_x - \\hat{\\tau}_x) + A } $$\n",
    "\n",
    "where $A=(\\tilde{\\beta}-\\hat{\\beta})^2 (\\hat{\\tau}_x (\\dot{\\beta}-\\tilde{\\beta})\\hat{\\sigma}^2_x ) + (\\tilde{\\beta}-\\hat{\\beta})^3(\\hat{\\tau}_x \\hat{\\sigma}^2_x - \\hat{\\tau}^2_x) $, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afc018",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulation results\n",
    "![Image](Figures/ArguableValidation_Figure_2.png)\n",
    "[Simulation Notebook](https://github.com/shoepaladin/statanomics/blob/main/workingcode/diagnostics/CoefficientStability.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c688c9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Drawbacks on Interpretation\n",
    "* Unlike the placebo test which you can either pass or fail based on whether the estimate on the placebo outcome is distinguishable from zero, the interpretation of coefficient stability is less clear.\n",
    "* Coefficient stability embraces the fact that selection bias is unavoidable and tells us how likely it is the selection bias will change our results or conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b871021c",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Need to elaborate that this assume the bias is a monotonic direction, which is why the $\\delta$^* bounces around a lot. It depends on whether the omitted variable has a positive or negative bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f8423",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample Interpretation\n",
    "* As a user, we need to make decide these values about unobserved features that cause selection bias: \n",
    "    * How much additional variation the unobserved features could potentially explain Y?;\n",
    "* The magnitude of the selection bias. • “We estimate a treatment effect of 10 and an $R^2=0.66$. We find $\\delta^∗=5$, suggesting that unobserved factors need to be 5 times as important as the observed ones to explain the remaining 1% of the outcome’s variation to bias our treatment effect by 15%.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51ebb1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature balancing \n",
    "#### aka covariate balancing\n",
    "Easiest to do, but needs it's own meta-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5b68a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "$$ Y_i = \\hat{\\tau} W_i + \\hat{\\beta}_1 X_i + \\eta_i$$\n",
    "\n",
    "* We can write the exogeneity condition as, “conditional on $X_i$, variation in $Y_i$ is the treatment effect.” \n",
    "* This means that if it weren’t for the treatment effect, the conditional difference between treatment and control is zero.\n",
    "* This is the “synthetic twin” idea – we estimate by comparing treatment and control groups that are otherwise similar.\n",
    "* Propensity score matching does just this, by comparing groups that have the same likelihood of being treated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c466730",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The primative to the big idea \n",
    "* A common practice in propensity score matching is to test whether matched treatment and control pairs are similar in $X_i$\n",
    "* The matched/adjusted sample should be more similar in $X_i$ than the raw/unadjusted sample. \n",
    "\n",
    "![Image](Figures/ArguableValidation_Figure_3.png)\n",
    "From [cobalt package](https://cran.r-project.org/web/packages/cobalt/vignettes/cobalt.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d144bf1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The big idea\n",
    "* We can do the same thing for any cross sectional model. This is because regression and weighting models do the same fundamental thing as matching.\n",
    "$$x_i = \\hat{\\pi}_x W_i + \\hat{\\alpha} \\hat{P}(X_i) + \\epsilon_i$$\n",
    "* Where $x_i$ is an element of $X_i$ and $\\hat{P}(X_i)$ is the estimated propensity score. \n",
    "* $\\hat{\\pi}$ estimates the “adjusted” difference in ௜ after matching. \n",
    "* If all $\\hat{\\pi}$ estimates are zero, then we can argue the unconfoundedness assumption is valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e0987",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementation\n",
    "1. Estimate propensity score, $\\hat{P}(X_i)$;\n",
    "2. Estimate $\\hat{\\pi}_x$ for all your $X_i$; \n",
    "3. Each time $\\hat{\\pi}_x$ cannot be distinguished from zero, you claim balance in $x$;\n",
    "4. Failure to pass suggests controlling for additional features, or being specific in caveats for interpretation.\n",
    "\n",
    "* You shouldn’t expect each estimate $\\hat{\\pi}_x$ to be indistinguishable from zero because of the multiple hypothesis testing problem.\n",
    "    * I like alpha-investing (following [Foster and Stein 2007](http://www-stat.wharton.upenn.edu/~stine/research/mfdr.pdf ) because you can prioritize what’s most important to balance on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accede8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Drawbacks \n",
    "* This approach requires you to be sure you have a good propensity score, $\\hat{P}(X_i)$.\n",
    "$$x_i = \\hat{\\pi}_x W_i + \\hat{\\alpha} \\hat{P}(X_i) + \\epsilon_i$$\n",
    "\n",
    "* Notice that $\\hat{P}(X_i)$ is estimated, so your confidence interval for $\\hat{\\pi}_x$ will be too small because you are not taking into account measurement error.\n",
    "* You need to bootstrap estimates of $\\hat{P}(X_i)$ to get the correct confidence interval for $\\hat{\\pi}_x$\n",
    "    * Therefore, you need to do two loops: \n",
    "        1. bootstrap $\\hat{P}(X_i)$; and \n",
    "        2. over $x \\in X_i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8256914",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulation\n",
    "* When exogeneity condition is true on the left hand side, the controlled differences are smaller.\n",
    "* When it is not true, feature balancing calls out which features we are imbalanced in\n",
    "\n",
    "\n",
    "| Controlling for $X_i$ | Controlling for some of $X_i$|\n",
    "|---|---|\n",
    "|<img src=\"Figures/ArguableValidation_Figure_4a.png\" width=\"200\" > |<img src=\"Figures/ArguableValidation_Figure_4b.png\" width=\"200\" > |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8fa6f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "<img src=\"Figures/ArguableValidation_Figure_1.png\" >\n",
    "\n",
    "* Four types of arguable validation for cross-sectional causal models\n",
    "* They all require interpretation of results and help you decide whether your assumption is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c1bed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Literature Review of Related Papers\n",
    "* Placebo Tests\n",
    "    * Imbens, Wooldridge. (2009). “Recent Developments in the Econometrics of Program Evaluation.” [link](https://www.nber.org/papers/w14251)\n",
    "    * Imbens. (2003). “Matching Methods in Practice: Three Examples.” [link](https://www.nber.org/papers/w19959)\n",
    "* Coefficient Stability\n",
    "    * Oster. (2019). “Unobservable Selection and Coefficient Stability: Theory and Evidence.” [link](https://www.nber.org/papers/w19054);\n",
    "    * Imbens. (2003). “Sensitivity to Exogeneity Assumptions in Program Evaluation.” [link](https://scholar.harvard.edu/imbens/files/sensitivity_to_exogeneity_assumptions_in_program_evaluation.pdf)\n",
    "* Feature Balancing\n",
    "    * Fan, Imai, Lee, Liu, Ning, Yang. (2014). “Covariate balancing propensity score.” [link](https://arxiv.org/abs/2108.01255)\n",
    "    * Sant’Anna, Song, Xu. (2018). “Covariate Distribution Balance via Propensity Scores.” [link](https://arxiv.org/abs/1810.01370)\n",
    "    * Athey, Imbens, Wager. (2016). “Approximate Residual Balancing: De-Biased Inference of Average Treatment Effects in High Dimensions.” [link](https://arxiv.org/abs/1604.07125)\n",
    "    * Ben-Miachel, Feller, Hirschberg, Zubizaretta. (2021). \"The Balancing Act in Causal Inference.” [link](https://arxiv.org/abs/2110.14831)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad2e51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Appendix Slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e6015c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conducting an experiment\n",
    "The hard work is at the setup, But you may not get you what you want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba8d08a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Big idea: create the randomization you wish you had\n",
    "$$ Y_i = \\hat{\\tau}^{obs} W_i + \\hat{\\beta}_1 X_i + \\eta_i$$\n",
    "\n",
    "* When we cannot run an experiment, we can use observational data. We want to control for $X_i$ to deal with selection bias.\n",
    "\n",
    "$$ Y_i = \\hat{\\tau}^{experimental} W_i + \\zeta_i$$\n",
    "\n",
    "* • If we could randomly assign $W_i$, then we will have no selection bias by design. We want to know whether $\\hat{\\tau}^{obs} = \\hat{\\tau}^{experimental }$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cdf832",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experimentation for validation\n",
    "\n",
    "* Conducting an experiment randomly assigning $W_i$ could validate our estimate of $\\tau$ \n",
    "* Observational and experimental analysis can be substitutes or complements:\n",
    "\n",
    "* Substitutes:\n",
    "    1. Do the experiment instead of observational analysis.\n",
    "* Complements:     \n",
    "    1. Use observational analysis to know where or how to conduct the experiment.\n",
    "    2. Experiment is designed to validate some of the observational results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79b05d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Drawbacks\n",
    "* You may not be able to randomly assign $W_i$\n",
    "    * For example, assigning random prices or purposely delaying deliveries\n",
    "* Experiments may be underpowered\n",
    "* Different experimental and observational samples may lead to incorrectly concluding $\\hat{\\tau}^{obs}$ is wrong. \n",
    "    * For example, different types of customers, different time periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df1349",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Placebo Type 2: Shift your Entire Dataset Back\n",
    "* Typically we run this, where $W_i$ occurs at $t=0$.\n",
    "$$ Y_{it} = \\hat{\\tau}^{obs} W_i + \\hat{\\beta}_1 X_{it} + \\eta_{it}$$\n",
    "* We can instead run the same regression assuming treatment happens at $t=-1$.\n",
    "\n",
    "$$ Y_{is} = \\hat{\\tau}^{obs} W_i + \\hat{\\beta}_1 X_{is} + \\eta_{is}$$\n",
    "* Where $s < -1$\n",
    "\n",
    "* You always use these controls and these outcomes. In this placebo approach, you pretend the treatment happened before it actually did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce660c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Placebo tests are not A/A tests\n",
    "\n",
    "* Instead of changing $Y_i$ to $Y_i^{pre}$, why do a hold-out approach of all control observations and we randomly assign $W_i$?\n",
    "* By randomly assigning $W_i$, we don’t have any selection biases to correct.\n",
    "    * Instead you would be doing diagnostics of how the regression performs when trained on the distribution of $Y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e23359",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimize for feature balance\n",
    "* The feature balancing described before has separate estimation steps for estimating the propensity score and the balancing test. \n",
    "* Why not incorporate feature balancing as an objective to estimating the propensity score?\n",
    "* Explored in a few papers:\n",
    "    * Sant’Anna, Song, Xu. https://arxiv.org/abs/1810.01370\n",
    "    * Athey, Imbens, Wager. https://arxiv.org/pdf/1604.07125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9a352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
