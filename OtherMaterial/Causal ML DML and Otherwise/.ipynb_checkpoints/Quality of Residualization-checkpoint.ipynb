{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8073009d",
   "metadata": {},
   "source": [
    "# Quality of Residualization\n",
    "Julian Hsu\n",
    "13-aug-2023\n",
    "\n",
    "We use this notebook to understand how the quality of residualization affects treatment estimates. We measure the quality of residualization with how well we can predict the outcome and treatment features. We use notation from Chernozhukov et al (2016) [Double-De-biased ML paper](https://arxiv.org/pdf/1608.00060.pdf). Specifically, we estimate two partial linear models using the residualized outcome, $\\tilde{Y}_i = Y_i - g_0(X_i)$, and the residualized treatment, $\\tilde{W}_i = W_i - m_0(X_i)$:\n",
    "\n",
    "$$ \\tilde{Y}_i = \\tau W_i + \\epsilon_i \\hspace{5cm} (EQ 1) $$\n",
    "$$ \\tilde{Y}_i = \\tau \\tilde{W}_i + \\eta_i \\hspace{5cm} (EQ 2) $$\n",
    "\n",
    "we first estimate $Y$ using a given ML model $g_0$, and then estimate an OLS regression of $Y_i - \\hat{Y_i}(X_i) = \\beta_0 + \\tau W_i + \\epsilon_i$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e51e768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57748cb0",
   "metadata": {},
   "source": [
    "## Write DGP Functions\n",
    "Write a DGP function with a treatment indicator and confounding features.\n",
    "\n",
    "The treatment effect will be a standard deviation of the potential control outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "abcceab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgp(N=1000,K=3,ate_sd = 0.1\n",
    "       , non_linear_degree=0\n",
    "       , log = False):\n",
    "    '''\n",
    "    N  number of rows\n",
    "    K  number of confounding variables\n",
    "    ate_sd  the impact in standard deviations of the outcome\n",
    "    non_linear_degree  what degree polynomial complexity we allow in outcome and treatment.\n",
    "    log  whether we take the log of the feature\n",
    "    '''\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    ## Create covariates\n",
    "    for k in range(K):\n",
    "        df_out['x{0:1.0f}'.format(k)] = np.random.uniform(1,3,N)\n",
    "            \n",
    "    if log==True:\n",
    "        df_x_features = np.log(df_out[[e for e in df_out.columns if 'x' in e]])\n",
    "    else:\n",
    "        df_x_features = df_out[[e for e in df_out.columns if 'x' in e]]\n",
    "\n",
    "    ## Create treatment indicator\n",
    "    t_array = np.random.uniform(-2,2,K) \n",
    "    w_latent = np.dot(df_x_features, t_array)    \n",
    "    if non_linear_degree <= 1:\n",
    "        pass\n",
    "    else:\n",
    "        t_array0 = np.random.uniform(-2,2,K) \n",
    "        test_w=np.dot(df_x_features.pow(non_linear_degree), t_array0)        \n",
    "        w_latent = w_latent + test_w\n",
    "    ## Scale this down for easier computation\n",
    "    w_latent /= np.var(w_latent)\n",
    "    w_latent /= np.abs(np.mean(w_latent))\n",
    "    w_latent = np.exp(w_latent) / (1+ np.exp(w_latent))  + np.random.uniform(0,1,N)\n",
    "    df_out['w'] = ( w_latent > np.percentile(w_latent, q=50) ).astype(float)\n",
    "    \n",
    "    ## Create outcome \n",
    "    y_array = np.random.uniform(-0.5,0.5,K)     \n",
    "    df_out['y'] = np.dot(df_x_features, y_array)\n",
    "    if non_linear_degree <= 1:\n",
    "        pass\n",
    "    else:\n",
    "        y_array0 = np.random.uniform(-2,2,K) \n",
    "        test_x = np.dot(df_x_features.pow(non_linear_degree), y_array0)  \n",
    "        df_out['y'] = df_out['y'] + test_x\n",
    "        df_out['test_x'] = test_x\n",
    "    \n",
    "    df_out['y'] += np.random.normal(0,2,N)\n",
    "\n",
    "    ate_to_use = ate_sd * df_out['y'].std()\n",
    "    df_out['y'] += df_out['w']*ate_to_use\n",
    "    \n",
    "    ## Scale this down for easier computation    \n",
    "    df_out['y'] /= np.mean(df_out['y'])\n",
    "        \n",
    "    \n",
    "    df_out['gt'] = ate_to_use\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "35960f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "10b31ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimate the treatment effect with sample-splitting\n",
    "## Also output the MAPE of outcome and treatment predictions\n",
    "def dml_estimate(data=None,X_list=None\n",
    "                , model_y=Ridge(alpha=1, fit_intercept=True)\n",
    "                , model_t=LogisticRegression(penalty='l2', C=1, fit_intercept=True)):\n",
    "    ml_t_model = model_t.fit(X=data[X_list], y = data['w'] )        \n",
    "    w_predictions = ml_t_model.predict_proba(data[X_list])[:,1].reshape(-1,1)\n",
    "    W = np.array(data['w']).reshape(-1,1) - w_predictions\n",
    "    \n",
    "    ml_model = model_y.fit(X=data[X_list], y = data['y'] )    \n",
    "    y_predictions = ml_model.predict(data[X_list])\n",
    "    YM = data['y'] - y_predictions\n",
    "\n",
    "    ## DML Estimate from PLM Model\n",
    "    \n",
    "    ols_model_r = LinearRegression(fit_intercept=True).fit(X=W, y = YM)\n",
    "        \n",
    "        \n",
    "    ## MAPE of the predictions and output\n",
    "    y_score=metrics.mean_squared_error(y_true=data['y'], y_pred=y_predictions)\n",
    "    w_score=metrics.roc_auc_score(y_true=data['w'], y_score=w_predictions)\n",
    "    \n",
    "    return ols_model_r.coef_[-1], y_score, w_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "af0c8cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Impact: 1.069\n",
      "DML Estimate: 26.468\n",
      "Y MSE:891.117, W MSE: 0.508\n"
     ]
    }
   ],
   "source": [
    "## Test run to check that the code works\n",
    "bias = []\n",
    "for s in range(200):\n",
    "    df = dgp(N=100, K=1, ate_sd = 0.5, non_linear_degree=1)\n",
    "    a= dml_estimate(data=df,X_list=['x0'] \n",
    "                    , model_y=Ridge(alpha=1, fit_intercept=True)\n",
    "                    , model_t=LogisticRegression(penalty='l2', C=1, fit_intercept=True) )\n",
    "    if s==0:\n",
    "        print('Ground Truth Impact: {0:5.3f}'.format(df['gt'][0]))\n",
    "        print('DML Estimate: {0:5.3f}'.format(a[0]))\n",
    "        print('Y MSE:{0:5.3f}, W MSE: {1:5.3f}'.format(a[1],a[2]))\n",
    "    bias.append(df['gt'][0] - a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ec5d2a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   1.,   0.,   0.,   1.,   0.,   2.,  15., 174.,   6.]),\n",
       " array([-174.35420104, -153.05231468, -131.75042832, -110.44854195,\n",
       "         -89.14665559,  -67.84476923,  -46.54288286,  -25.2409965 ,\n",
       "          -3.93911014,   17.36277623,   38.66466259]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803028eb",
   "metadata": {},
   "source": [
    "## Simulations Demonstrating Relationship between Fit and Bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39264079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()\n",
    "Stimes = 100\n",
    "degree_complexity_list = [1,5]\n",
    "for deg in degree_complexity_list:\n",
    "    for s in range(Stimes):\n",
    "        df = dgp(N=2000, K=2, ate_sd = 0.5, non_linear_degree=deg)\n",
    "\n",
    "        dml_result = dml_estimate(data=df, X_list=['x0','x1']\n",
    "                , model_y=LinearRegression()\n",
    "                , model_t=LogisticRegression(penalty='none') )\n",
    "        gt = df['gt'][0]\n",
    "        entry = pd.DataFrame(index=[s]\n",
    "                    , data=dict(zip(['estimate','y_mse','w_roc_auc'],dml_result)))\n",
    "        entry['complexity']=deg\n",
    "        entry['gt']=gt\n",
    "        df_results = pd.concat([df_results, entry  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['bias'] = df_results['estimate'] - df_results['gt']        \n",
    "df_results['bias_mape'] = np.abs(df_results['estimate'] - df_results['gt']/df_results['gt']  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf825276",
   "metadata": {},
   "source": [
    "Normalized the MSE and ROC AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21498d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in ['y_mse','w_roc_auc']:\n",
    "    if s=='w_roc_auc':\n",
    "        df_results[s+'_perc'] = np.abs(df_results[s]).rank(pct=True, ascending=True, method='max')\n",
    "    else:\n",
    "        df_results[s+'_perc'] = np.abs(df_results[s]).rank(pct=True, ascending=False, method='max')\n",
    "    \n",
    "    \n",
    "#     df_results[s] = (df_results[s] - df_results[s].mean()) / df_results[s].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[['bias','bias_mape','y_mse','w_roc_auc']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_corr_data(xe=None, ye=None ,axes=None, plot_color=None):\n",
    "    lr_fit = LinearRegression(fit_intercept=True).fit(np.array(xe).reshape(-1, 1) , ye) \n",
    "    x_predict= np.array([np.min(xe), np\n",
    "                .max(xe)]).reshape(-1,1)\n",
    "    y_predict=lr_fit.predict( x_predict )\n",
    "    axes.plot(x_predict, y_predict, color='black', linewidth=5, linestyle='--', alpha=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d019e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "for deg in enumerate(degree_complexity_list):\n",
    "    fig,ax = plt.subplots(ncols=2,nrows=1,figsize=(10,5), sharey=True)\n",
    "    plot_ = df_results.loc[(df_results['complexity']==deg[1]) ]\n",
    "\n",
    "    ## Remove rows with the 2 highest mse values\n",
    "    plot_ = plot_.sort_values(by=['y_mse_perc'],ascending=False)[2:]\n",
    "    plot_ = plot_.sort_values(by=['w_roc_auc_perc'],ascending=False)[2:]\n",
    "    plot_ = plot_.sort_values(by=['bias'],ascending=False)[2:]\n",
    "\n",
    "    plot_['bias'] = np.abs(plot_['bias'])\n",
    "\n",
    "    at0=ax[0].scatter(y=plot_['bias'], x=plot_['y_mse_perc'], alpha=0.75, color='royalblue',label='Outcome (MSE)')\n",
    "#     plot_corr_data(xe=plot_['y_mse_perc'], ye=plot_['bias'], axes=ax[0], plot_color=at0.get_edgecolor())\n",
    "    ax[0].set_title('Prediction Performance\\n of Outcome (MSE)', color='white')\n",
    "    \n",
    "    at1=ax[1].scatter(y=plot_['bias'], x=plot_['w_roc_auc_perc'], alpha=0.75, color='seagreen', label='Treatment (ROC AUC)')\n",
    "#     plot_corr_data(xe=plot_['w_roc_auc_perc'], ye=plot_['bias'], axes=ax[1], plot_color=at1.get_edgecolor())\n",
    "    ax[1].set_title('Prediction Performance\\n of Treatment (ROC-AUC)', color='white')\n",
    "    \n",
    "#     ax[deg[0],1].legend( bbox_to_anchor=(1.04, 1), loc=\"upper left\", fancybox=True)\n",
    "#     ax[deg[0],1].legend( bbox_to_anchor=(1.04, 1), loc=\"upper left\", fancybox=True)\n",
    "    \n",
    "    for e in range(2):\n",
    "        ax[e].set_xlabel('Prediction Performance')\n",
    "        ax[e].set_xticks([0.1, 0.5, 0.9])\n",
    "        ax[e].set_xticklabels(['low','medium','high'])    \n",
    "        ax[e].set_ylabel(r'Bias')\n",
    "        ax[e].set_facecolor('lightyellow')\n",
    "        ax[e].grid()\n",
    "        ax[e].xaxis.label.set_color('white')\n",
    "        ax[e].yaxis.label.set_color('white')\n",
    "        ax[e].tick_params(axis='x', colors='white')\n",
    "        ax[e].tick_params(axis='y', colors='white')\n",
    "\n",
    "    \n",
    "#     fig.suptitle(r'Scatterplots of treatment effect biases\\n on outcome and treatment prediction performance\\n results from a DML model using unpenalized linear regression and logistic regression to residualize.', color='white')\n",
    "    \n",
    "    if deg[1]<=1:\n",
    "        fig.suptitle(r'Data generated as $y \\sim w, x$'.format(deg[1]), color='white')\n",
    "    else:\n",
    "        fig.suptitle(r'Data generated as $y \\sim w, x, x^{0}$'.format(deg[1]), color='white')\n",
    "\n",
    "        \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.set_facecolor('maroon')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe894f41",
   "metadata": {},
   "source": [
    "**sound byte** How important is it to iterate on the prediction parts of your double machine learnin (DML) model? I show with simulation evidence that there are diminishing returns to improving your prediction models. I show here the relationship between better predicting the outcome and treatment indicator and bias of the DML estimate. As expected, improving your prediction reduces the bias of your estimate. However, I find that there are greater benefits from reducing variation in your outcome variable. Note in these simulation have selection bias: treatment is not randomly assigned.\n",
    "\n",
    "I'm curious how others view this, especially since residualization in only the outcome or treatment leads to bias as I find here ( [post](https://www.linkedin.com/posts/jhsuecon_causalinference-machinelearning-activity-7087083617868263424-EmCo?utm_source=share&utm_medium=member_desktop) / [notebook](https://github.com/shoepaladin/causalinference_crashcourse/blob/main/OtherMaterial/Causal%20ML%20DML%20and%20Otherwise/Causal%20Inference%20versus%20Prediction%20in%20Linear%20Regression%20Models.ipynb) ). \n",
    "\n",
    "Check out the notebook used to generate it here!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
